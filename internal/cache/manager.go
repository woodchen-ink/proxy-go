package cache

import (
	"crypto/sha256"
	"encoding/hex"
	"fmt"
	"hash/fnv"
	"log"
	"net/http"
	"os"
	"path/filepath"
	"proxy-go/internal/config"
	"proxy-go/internal/utils"
	"sort"
	"strings"
	"sync"
	"sync/atomic"
	"time"
)

// å†…å­˜æ± ç”¨äºå¤ç”¨ç¼“å†²åŒº
var (
	bufferPool = sync.Pool{
		New: func() interface{} {
			return make([]byte, 32*1024) // 32KB ç¼“å†²åŒº
		},
	}

	// å¤§ç¼“å†²åŒºæ± ï¼ˆç”¨äºå¤§æ–‡ä»¶ï¼‰
	largeBufPool = sync.Pool{
		New: func() interface{} {
			return make([]byte, 1024*1024) // 1MB ç¼“å†²åŒº
		},
	}
)

// GetBuffer ä»æ± ä¸­è·å–ç¼“å†²åŒº
func GetBuffer(size int) []byte {
	if size <= 32*1024 {
		buf := bufferPool.Get().([]byte)
		if cap(buf) >= size {
			return buf[:size]
		}
		bufferPool.Put(buf)
	} else if size <= 1024*1024 {
		buf := largeBufPool.Get().([]byte)
		if cap(buf) >= size {
			return buf[:size]
		}
		largeBufPool.Put(buf)
	}
	// å¦‚æœæ± ä¸­çš„ç¼“å†²åŒºä¸å¤Ÿå¤§ï¼Œåˆ›å»ºæ–°çš„
	return make([]byte, size)
}

// PutBuffer å°†ç¼“å†²åŒºæ”¾å›æ± ä¸­
func PutBuffer(buf []byte) {
	if cap(buf) == 32*1024 {
		bufferPool.Put(buf)
	} else if cap(buf) == 1024*1024 {
		largeBufPool.Put(buf)
	}
	// å…¶ä»–å¤§å°çš„ç¼“å†²åŒºè®©GCå¤„ç†
}

// LRU ç¼“å­˜èŠ‚ç‚¹
type LRUNode struct {
	key   CacheKey
	value *CacheItem
	prev  *LRUNode
	next  *LRUNode
}

// LRU ç¼“å­˜å®ç°
type LRUCache struct {
	capacity int
	size     int
	head     *LRUNode
	tail     *LRUNode
	cache    map[CacheKey]*LRUNode
	mu       sync.RWMutex
}

// NewLRUCache åˆ›å»ºLRUç¼“å­˜
func NewLRUCache(capacity int) *LRUCache {
	lru := &LRUCache{
		capacity: capacity,
		cache:    make(map[CacheKey]*LRUNode),
		head:     &LRUNode{},
		tail:     &LRUNode{},
	}
	lru.head.next = lru.tail
	lru.tail.prev = lru.head
	return lru
}

// Get ä»LRUç¼“å­˜ä¸­è·å–
func (lru *LRUCache) Get(key CacheKey) (*CacheItem, bool) {
	lru.mu.Lock()
	defer lru.mu.Unlock()

	if node, exists := lru.cache[key]; exists {
		lru.moveToHead(node)
		return node.value, true
	}
	return nil, false
}

// Put å‘LRUç¼“å­˜ä¸­æ·»åŠ 
func (lru *LRUCache) Put(key CacheKey, value *CacheItem) {
	lru.mu.Lock()
	defer lru.mu.Unlock()

	if node, exists := lru.cache[key]; exists {
		node.value = value
		lru.moveToHead(node)
	} else {
		newNode := &LRUNode{key: key, value: value}
		lru.cache[key] = newNode
		lru.addToHead(newNode)
		lru.size++

		if lru.size > lru.capacity {
			tail := lru.removeTail()
			delete(lru.cache, tail.key)
			lru.size--
		}
	}
}

// Delete ä»LRUç¼“å­˜ä¸­åˆ é™¤
func (lru *LRUCache) Delete(key CacheKey) {
	lru.mu.Lock()
	defer lru.mu.Unlock()

	if node, exists := lru.cache[key]; exists {
		lru.removeNode(node)
		delete(lru.cache, key)
		lru.size--
	}
}

// moveToHead å°†èŠ‚ç‚¹ç§»åˆ°å¤´éƒ¨
func (lru *LRUCache) moveToHead(node *LRUNode) {
	lru.removeNode(node)
	lru.addToHead(node)
}

// addToHead æ·»åŠ åˆ°å¤´éƒ¨
func (lru *LRUCache) addToHead(node *LRUNode) {
	node.prev = lru.head
	node.next = lru.head.next
	lru.head.next.prev = node
	lru.head.next = node
}

// removeNode ç§»é™¤èŠ‚ç‚¹
func (lru *LRUCache) removeNode(node *LRUNode) {
	node.prev.next = node.next
	node.next.prev = node.prev
}

// removeTail ç§»é™¤å°¾éƒ¨èŠ‚ç‚¹
func (lru *LRUCache) removeTail() *LRUNode {
	lastNode := lru.tail.prev
	lru.removeNode(lastNode)
	return lastNode
}

// Range éå†æ‰€æœ‰ç¼“å­˜é¡¹
func (lru *LRUCache) Range(fn func(key CacheKey, value *CacheItem) bool) {
	lru.mu.RLock()
	defer lru.mu.RUnlock()

	for key, node := range lru.cache {
		if !fn(key, node.value) {
			break
		}
	}
}

// Size è¿”å›ç¼“å­˜å¤§å°
func (lru *LRUCache) Size() int {
	lru.mu.RLock()
	defer lru.mu.RUnlock()
	return lru.size
}

// CacheKey ç”¨äºæ ‡è¯†ç¼“å­˜é¡¹çš„å”¯ä¸€é”®
type CacheKey struct {
	URL           string
	AcceptHeaders string
	UserAgent     string
}

// String å®ç° Stringer æ¥å£ï¼Œç”¨äºç”Ÿæˆå”¯ä¸€çš„å­—ç¬¦ä¸²è¡¨ç¤º
func (k CacheKey) String() string {
	return fmt.Sprintf("%s|%s|%s", k.URL, k.AcceptHeaders, k.UserAgent)
}

// Equal æ¯”è¾ƒä¸¤ä¸ª CacheKey æ˜¯å¦ç›¸ç­‰
func (k CacheKey) Equal(other CacheKey) bool {
	return k.URL == other.URL &&
		k.AcceptHeaders == other.AcceptHeaders &&
		k.UserAgent == other.UserAgent
}

// Hash ç”Ÿæˆ CacheKey çš„å“ˆå¸Œå€¼
func (k CacheKey) Hash() uint64 {
	h := fnv.New64a()
	h.Write([]byte(k.String()))
	return h.Sum64()
}

// CacheItem è¡¨ç¤ºä¸€ä¸ªç¼“å­˜é¡¹
type CacheItem struct {
	FilePath        string
	ContentType     string
	ContentEncoding string
	Size            int64
	LastAccess      time.Time
	Hash            string
	CreatedAt       time.Time
	AccessCount     int64
	Priority        int // ç¼“å­˜ä¼˜å…ˆçº§
}

// CacheStats ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
type CacheStats struct {
	TotalItems        int     `json:"total_items"`         // ç¼“å­˜é¡¹æ•°é‡
	TotalSize         int64   `json:"total_size"`          // æ€»å¤§å°
	HitCount          int64   `json:"hit_count"`           // å‘½ä¸­æ¬¡æ•°
	MissCount         int64   `json:"miss_count"`          // æœªå‘½ä¸­æ¬¡æ•°
	HitRate           float64 `json:"hit_rate"`            // å‘½ä¸­ç‡
	BytesSaved        int64   `json:"bytes_saved"`         // èŠ‚çœçš„å¸¦å®½
	Enabled           bool    `json:"enabled"`             // ç¼“å­˜å¼€å…³çŠ¶æ€
	FormatFallbackHit int64   `json:"format_fallback_hit"` // æ ¼å¼å›é€€å‘½ä¸­æ¬¡æ•°
	ImageCacheHit     int64   `json:"image_cache_hit"`     // å›¾ç‰‡ç¼“å­˜å‘½ä¸­æ¬¡æ•°
	RegularCacheHit   int64   `json:"regular_cache_hit"`   // å¸¸è§„ç¼“å­˜å‘½ä¸­æ¬¡æ•°
}

// CacheManager ç¼“å­˜ç®¡ç†å™¨
type CacheManager struct {
	cacheDir     string
	items        sync.Map  // ä¿æŒåŸæœ‰çš„ sync.Map ç”¨äºæ–‡ä»¶ç¼“å­˜
	lruCache     *LRUCache // æ–°å¢LRUç¼“å­˜ç”¨äºçƒ­ç‚¹æ•°æ®
	maxAge       time.Duration
	cleanupTick  time.Duration
	maxCacheSize int64
	enabled      atomic.Bool   // ç¼“å­˜å¼€å…³
	hitCount     atomic.Int64  // å‘½ä¸­è®¡æ•°
	missCount    atomic.Int64  // æœªå‘½ä¸­è®¡æ•°
	bytesSaved   atomic.Int64  // èŠ‚çœçš„å¸¦å®½
	cleanupTimer *time.Ticker  // æ·»åŠ æ¸…ç†å®šæ—¶å™¨
	stopCleanup  chan struct{} // æ·»åŠ åœæ­¢ä¿¡å·é€šé“

	// æ–°å¢ï¼šæ ¼å¼å›é€€ç»Ÿè®¡
	formatFallbackHit atomic.Int64 // æ ¼å¼å›é€€å‘½ä¸­æ¬¡æ•°
	imageCacheHit     atomic.Int64 // å›¾ç‰‡ç¼“å­˜å‘½ä¸­æ¬¡æ•°
	regularCacheHit   atomic.Int64 // å¸¸è§„ç¼“å­˜å‘½ä¸­æ¬¡æ•°

	// ExtensionMatcherç¼“å­˜
	extensionMatcherCache *ExtensionMatcherCache
}

// NewCacheManager åˆ›å»ºæ–°çš„ç¼“å­˜ç®¡ç†å™¨
func NewCacheManager(cacheDir string, initialConfig *config.CacheConfig) (*CacheManager, error) {
	if err := os.MkdirAll(cacheDir, 0755); err != nil {
		return nil, fmt.Errorf("failed to create cache directory: %v", err)
	}

	cm := &CacheManager{
		cacheDir:     cacheDir,
		lruCache:     NewLRUCache(10000), // 10000ä¸ªçƒ­ç‚¹ç¼“å­˜é¡¹
		stopCleanup:  make(chan struct{}),

		// åˆå§‹åŒ–ExtensionMatcherç¼“å­˜
		extensionMatcherCache: NewExtensionMatcherCache(),
	}

	cm.enabled.Store(true) // é»˜è®¤å¯ç”¨ç¼“å­˜

	// åº”ç”¨åˆå§‹é…ç½®ï¼Œå¯¹äº0å€¼ä½¿ç”¨é»˜è®¤å€¼
	if initialConfig != nil && initialConfig.MaxAge > 0 && initialConfig.CleanupTick > 0 && initialConfig.MaxCacheSize > 0 {
		cm.maxAge = time.Duration(initialConfig.MaxAge) * time.Minute
		cm.cleanupTick = time.Duration(initialConfig.CleanupTick) * time.Minute
		cm.maxCacheSize = initialConfig.MaxCacheSize * 1024 * 1024 * 1024 // è½¬æ¢ä¸ºå­—èŠ‚
	} else {
		// ä½¿ç”¨é»˜è®¤å€¼ï¼ˆå½“é…ç½®ä¸ºnilæˆ–åŒ…å«0å€¼æ—¶ï¼‰
		cm.maxAge = 30 * time.Minute
		cm.cleanupTick = 5 * time.Minute
		cm.maxCacheSize = 10 * 1024 * 1024 * 1024 // 10GB
		log.Printf("[Cache] Using default cache config (maxAge: 30min, cleanupTick: 5min, maxSize: 10GB)")
	}

	// å¯åŠ¨æ—¶æ¸…ç†è¿‡æœŸå’Œä¸´æ—¶æ–‡ä»¶
	if err := cm.cleanStaleFiles(); err != nil {
		log.Printf("[Cache] Failed to clean stale files: %v", err)
	}

	// å¯åŠ¨æ¸…ç†åç¨‹
	cm.startCleanup()

	return cm, nil
}

// GenerateCacheKey ç”Ÿæˆç¼“å­˜é”®
func (cm *CacheManager) GenerateCacheKey(r *http.Request) CacheKey {
	// å¤„ç† Vary å¤´éƒ¨
	varyHeaders := make([]string, 0)
	for _, vary := range strings.Split(r.Header.Get("Vary"), ",") {
		vary = strings.TrimSpace(vary)
		if vary != "" {
			value := r.Header.Get(vary)
			varyHeaders = append(varyHeaders, vary+"="+value)
		}
	}
	sort.Strings(varyHeaders)

	url := r.URL.String()
	acceptHeaders := r.Header.Get("Accept")
	userAgent := r.Header.Get("User-Agent")

	// ğŸ¯ é’ˆå¯¹å›¾ç‰‡è¯·æ±‚è¿›è¡Œæ™ºèƒ½ç¼“å­˜é”®ä¼˜åŒ–
	if utils.IsImageRequest(r.URL.Path) {
		// è§£æAcceptå¤´ä¸­çš„å›¾ç‰‡æ ¼å¼åå¥½
		imageFormat := cm.parseImageFormatPreference(acceptHeaders)

		// ä¸ºå›¾ç‰‡è¯·æ±‚ç”Ÿæˆæ ¼å¼æ„ŸçŸ¥çš„ç¼“å­˜é”®
		return CacheKey{
			URL:           url,
			AcceptHeaders: imageFormat,                      // ä½¿ç”¨æ ‡å‡†åŒ–çš„å›¾ç‰‡æ ¼å¼
			UserAgent:     cm.normalizeUserAgent(userAgent), // æ ‡å‡†åŒ–UserAgent
		}
	}

	return CacheKey{
		URL:           url,
		AcceptHeaders: acceptHeaders,
		UserAgent:     userAgent,
	}
}

// parseImageFormatPreference è§£æå›¾ç‰‡æ ¼å¼åå¥½ï¼Œè¿”å›æ ‡å‡†åŒ–çš„æ ¼å¼æ ‡è¯†
func (cm *CacheManager) parseImageFormatPreference(accept string) string {
	if accept == "" {
		return "image/jpeg" // é»˜è®¤æ ¼å¼
	}

	accept = strings.ToLower(accept)

	// æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥ç°ä»£å›¾ç‰‡æ ¼å¼
	switch {
	case strings.Contains(accept, "image/avif"):
		return "image/avif"
	case strings.Contains(accept, "image/webp"):
		return "image/webp"
	case strings.Contains(accept, "image/jpeg") || strings.Contains(accept, "image/jpg"):
		return "image/jpeg"
	case strings.Contains(accept, "image/png"):
		return "image/png"
	case strings.Contains(accept, "image/gif"):
		return "image/gif"
	case strings.Contains(accept, "image/*"):
		return "image/auto" // è‡ªåŠ¨æ ¼å¼
	default:
		return "image/jpeg" // é»˜è®¤æ ¼å¼
	}
}

// normalizeUserAgent æ ‡å‡†åŒ–UserAgentï¼Œå‡å°‘ç¼“å­˜é”®çš„å˜åŒ–
func (cm *CacheManager) normalizeUserAgent(ua string) string {
	if ua == "" {
		return "default"
	}

	ua = strings.ToLower(ua)

	// æ ¹æ®ä¸»è¦æµè§ˆå™¨ç±»å‹è¿›è¡Œåˆ†ç±»
	switch {
	case strings.Contains(ua, "chrome") && !strings.Contains(ua, "edge"):
		return "chrome"
	case strings.Contains(ua, "firefox"):
		return "firefox"
	case strings.Contains(ua, "safari") && !strings.Contains(ua, "chrome"):
		return "safari"
	case strings.Contains(ua, "edge"):
		return "edge"
	case strings.Contains(ua, "bot") || strings.Contains(ua, "crawler"):
		return "bot"
	default:
		return "other"
	}
}

// Get è·å–ç¼“å­˜é¡¹
func (cm *CacheManager) Get(key CacheKey, r *http.Request) (*CacheItem, bool, bool) {
	if !cm.enabled.Load() {
		return nil, false, false
	}

	// ğŸ¯ é’ˆå¯¹å›¾ç‰‡è¯·æ±‚å®ç°æ™ºèƒ½æ ¼å¼å›é€€
	if utils.IsImageRequest(r.URL.Path) {
		return cm.getImageWithFallback(key, r)
	}

	return cm.getRegularItem(key)
}

// getImageWithFallback è·å–å›¾ç‰‡ç¼“å­˜é¡¹ï¼Œæ”¯æŒæ ¼å¼å›é€€
func (cm *CacheManager) getImageWithFallback(key CacheKey, r *http.Request) (*CacheItem, bool, bool) {
	// é¦–å…ˆå°è¯•ç²¾ç¡®åŒ¹é…
	if item, found, notModified := cm.getRegularItem(key); found {
		cm.imageCacheHit.Add(1)
		return item, found, notModified
	}

	// å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•æ ¼å¼å›é€€
	if item, found, notModified := cm.tryFormatFallback(key, r); found {
		cm.formatFallbackHit.Add(1)
		return item, found, notModified
	}

	return nil, false, false
}

// tryFormatFallback å°è¯•æ ¼å¼å›é€€
func (cm *CacheManager) tryFormatFallback(originalKey CacheKey, r *http.Request) (*CacheItem, bool, bool) {
	requestedFormat := originalKey.AcceptHeaders

	// å®šä¹‰æ ¼å¼å›é€€é¡ºåº
	fallbackFormats := cm.getFormatFallbackOrder(requestedFormat)

	for _, format := range fallbackFormats {
		fallbackKey := CacheKey{
			URL:           originalKey.URL,
			AcceptHeaders: format,
			UserAgent:     originalKey.UserAgent,
		}

		if item, found, notModified := cm.getRegularItem(fallbackKey); found {
			// æ‰¾åˆ°äº†å…¼å®¹æ ¼å¼ï¼Œæ£€æŸ¥æ˜¯å¦çœŸçš„å…¼å®¹
			if cm.isFormatCompatible(requestedFormat, format, item.ContentType) {
				log.Printf("[Cache] æ ¼å¼å›é€€: %s -> %s (%s)", requestedFormat, format, originalKey.URL)
				return item, found, notModified
			}
		}
	}

	return nil, false, false
}

// getFormatFallbackOrder è·å–æ ¼å¼å›é€€é¡ºåº
func (cm *CacheManager) getFormatFallbackOrder(requestedFormat string) []string {
	switch requestedFormat {
	case "image/avif":
		return []string{"image/webp", "image/jpeg", "image/png"}
	case "image/webp":
		return []string{"image/jpeg", "image/png", "image/avif"}
	case "image/jpeg":
		return []string{"image/webp", "image/png", "image/avif"}
	case "image/png":
		return []string{"image/webp", "image/jpeg", "image/avif"}
	case "image/auto":
		return []string{"image/webp", "image/avif", "image/jpeg", "image/png"}
	default:
		return []string{"image/jpeg", "image/webp", "image/png"}
	}
}

// isFormatCompatible æ£€æŸ¥æ ¼å¼æ˜¯å¦å…¼å®¹
func (cm *CacheManager) isFormatCompatible(requestedFormat, cachedFormat, actualContentType string) bool {
	// å¦‚æœæ˜¯è‡ªåŠ¨æ ¼å¼ï¼Œæ¥å—ä»»ä½•ç°ä»£æ ¼å¼
	if requestedFormat == "image/auto" {
		return true
	}

	// ç°ä»£æµè§ˆå™¨é€šå¸¸å¯ä»¥å¤„ç†å¤šç§æ ¼å¼
	modernFormats := map[string]bool{
		"image/webp": true,
		"image/avif": true,
		"image/jpeg": true,
		"image/png":  true,
	}

	// æ£€æŸ¥å®é™…å†…å®¹ç±»å‹æ˜¯å¦ä¸ºç°ä»£æ ¼å¼
	if actualContentType != "" {
		return modernFormats[strings.ToLower(actualContentType)]
	}

	return modernFormats[cachedFormat]
}

// getRegularItem è·å–å¸¸è§„ç¼“å­˜é¡¹ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
func (cm *CacheManager) getRegularItem(key CacheKey) (*CacheItem, bool, bool) {
	// æ£€æŸ¥LRUç¼“å­˜
	if item, found := cm.lruCache.Get(key); found {
		// æ£€æŸ¥LRUç¼“å­˜é¡¹æ˜¯å¦è¿‡æœŸ
		if time.Since(item.LastAccess) > cm.maxAge {
			cm.lruCache.Delete(key)
			cm.missCount.Add(1)
			return nil, false, false
		}
		// æ›´æ–°è®¿é—®æ—¶é—´
		item.LastAccess = time.Now()
		atomic.AddInt64(&item.AccessCount, 1)
		cm.hitCount.Add(1)
		cm.regularCacheHit.Add(1)
		return item, true, false
	}

	// æ£€æŸ¥æ–‡ä»¶ç¼“å­˜
	value, ok := cm.items.Load(key)
	if !ok {
		cm.missCount.Add(1)
		return nil, false, false
	}

	item := value.(*CacheItem)

	// éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
	if _, err := os.Stat(item.FilePath); err != nil {
		cm.items.Delete(key)
		cm.missCount.Add(1)
		return nil, false, false
	}

	// æ£€æŸ¥æ˜¯å¦è¿‡æœŸï¼ˆä½¿ç”¨LastAccessè€Œä¸æ˜¯CreatedAtï¼‰
	if time.Since(item.LastAccess) > cm.maxAge {
		cm.items.Delete(key)
		os.Remove(item.FilePath)
		cm.missCount.Add(1)
		return nil, false, false
	}

	// æ›´æ–°è®¿é—®ä¿¡æ¯ï¼ˆé‡ç½®è¿‡æœŸæ—¶é—´ï¼‰
	item.LastAccess = time.Now()
	atomic.AddInt64(&item.AccessCount, 1)
	cm.hitCount.Add(1)
	cm.regularCacheHit.Add(1)
	cm.bytesSaved.Add(item.Size)

	// å°†ç¼“å­˜é¡¹æ·»åŠ åˆ°LRUç¼“å­˜
	cm.lruCache.Put(key, item)

	return item, true, false
}

// Put æ·»åŠ ç¼“å­˜é¡¹
func (cm *CacheManager) Put(key CacheKey, resp *http.Response, body []byte) (*CacheItem, error) {
	// åªæ£€æŸ¥åŸºæœ¬çš„å“åº”çŠ¶æ€
	if resp.StatusCode != http.StatusOK {
		return nil, fmt.Errorf("response status not OK")
	}

	// è®¡ç®—å†…å®¹å“ˆå¸Œ
	contentHash := sha256.Sum256(body)
	hashStr := hex.EncodeToString(contentHash[:])

	// æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç›¸åŒå“ˆå¸Œçš„ç¼“å­˜é¡¹
	var existingItem *CacheItem
	cm.items.Range(func(k, v interface{}) bool {
		if item := v.(*CacheItem); item.Hash == hashStr {
			if _, err := os.Stat(item.FilePath); err == nil {
				existingItem = item
				return false
			}
			cm.items.Delete(k)
		}
		return true
	})

	if existingItem != nil {
		cm.items.Store(key, existingItem)
		log.Printf("[Cache] HIT %s %s (%s) from %s", resp.Request.Method, key.URL, formatBytes(existingItem.Size), utils.GetRequestSource(resp.Request))
		return existingItem, nil
	}

	// ç”Ÿæˆæ–‡ä»¶åå¹¶å­˜å‚¨
	fileName := hashStr
	filePath := filepath.Join(cm.cacheDir, fileName)

	if err := os.WriteFile(filePath, body, 0600); err != nil {
		return nil, fmt.Errorf("failed to write cache file: %v", err)
	}

	item := &CacheItem{
		FilePath:        filePath,
		ContentType:     resp.Header.Get("Content-Type"),
		ContentEncoding: resp.Header.Get("Content-Encoding"),
		Size:            int64(len(body)),
		LastAccess:      time.Now(),
		Hash:            hashStr,
		CreatedAt:       time.Now(),
		AccessCount:     1,
	}

	cm.items.Store(key, item)
	method := "GET"
	if resp.Request != nil {
		method = resp.Request.Method
	}
	log.Printf("[Cache] NEW %s %s (%s) from %s", method, key.URL, formatBytes(item.Size), utils.GetRequestSource(resp.Request))
	return item, nil
}

// cleanup å®šæœŸæ¸…ç†è¿‡æœŸçš„ç¼“å­˜é¡¹
func (cm *CacheManager) cleanup() {
	var totalSize int64
	var keysToDelete []CacheKey

	// æ”¶é›†éœ€è¦åˆ é™¤çš„é”®å’Œè®¡ç®—æ€»å¤§å°
	cm.items.Range(func(k, v interface{}) bool {
		key := k.(CacheKey)
		item := v.(*CacheItem)
		totalSize += item.Size

		if time.Since(item.LastAccess) > cm.maxAge {
			keysToDelete = append(keysToDelete, key)
		}
		return true
	})

	// å¦‚æœæ€»å¤§å°è¶…è¿‡é™åˆ¶ï¼ŒæŒ‰æœ€åè®¿é—®æ—¶é—´æ’åºåˆ é™¤
	if totalSize > cm.maxCacheSize {
		var items []*CacheItem
		cm.items.Range(func(k, v interface{}) bool {
			items = append(items, v.(*CacheItem))
			return true
		})

		// æŒ‰æœ€åè®¿é—®æ—¶é—´æ’åº
		sort.Slice(items, func(i, j int) bool {
			return items[i].LastAccess.Before(items[j].LastAccess)
		})

		// åˆ é™¤æœ€æ—§çš„é¡¹ç›´åˆ°æ€»å¤§å°å°äºé™åˆ¶
		for _, item := range items {
			if totalSize <= cm.maxCacheSize {
				break
			}
			cm.items.Range(func(k, v interface{}) bool {
				if v.(*CacheItem) == item {
					keysToDelete = append(keysToDelete, k.(CacheKey))
					totalSize -= item.Size
					return false
				}
				return true
			})
		}
	}

	// åˆ é™¤è¿‡æœŸå’Œè¶…å‡ºå¤§å°é™åˆ¶çš„ç¼“å­˜é¡¹
	for _, key := range keysToDelete {
		if item, ok := cm.items.Load(key); ok {
			cacheItem := item.(*CacheItem)
			os.Remove(cacheItem.FilePath)
			cm.items.Delete(key)
			log.Printf("[Cache] DEL %s (expired)", key.URL)
		}
	}
}

// formatBytes æ ¼å¼åŒ–å­—èŠ‚å¤§å°
func formatBytes(bytes int64) string {
	const (
		KB = 1024
		MB = 1024 * KB
		GB = 1024 * MB
	)

	switch {
	case bytes >= GB:
		return fmt.Sprintf("%.2f GB", float64(bytes)/float64(GB))
	case bytes >= MB:
		return fmt.Sprintf("%.2f MB", float64(bytes)/float64(MB))
	case bytes >= KB:
		return fmt.Sprintf("%.2f KB", float64(bytes)/float64(KB))
	default:
		return fmt.Sprintf("%d B", bytes)
	}
}

// GetStats è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
func (cm *CacheManager) GetStats() CacheStats {
	var totalItems int
	var totalSize int64

	cm.items.Range(func(_, value interface{}) bool {
		item := value.(*CacheItem)
		totalItems++
		totalSize += item.Size
		return true
	})

	hitCount := cm.hitCount.Load()
	missCount := cm.missCount.Load()
	totalRequests := hitCount + missCount
	hitRate := float64(0)
	if totalRequests > 0 {
		hitRate = float64(hitCount) / float64(totalRequests) * 100
	}

	return CacheStats{
		TotalItems:        totalItems,
		TotalSize:         totalSize,
		HitCount:          hitCount,
		MissCount:         missCount,
		HitRate:           hitRate,
		BytesSaved:        cm.bytesSaved.Load(),
		Enabled:           cm.enabled.Load(),
		FormatFallbackHit: cm.formatFallbackHit.Load(),
		ImageCacheHit:     cm.imageCacheHit.Load(),
		RegularCacheHit:   cm.regularCacheHit.Load(),
	}
}

// SetEnabled è®¾ç½®ç¼“å­˜å¼€å…³çŠ¶æ€
func (cm *CacheManager) SetEnabled(enabled bool) {
	cm.enabled.Store(enabled)
}

// ClearCache æ¸…ç©ºç¼“å­˜
func (cm *CacheManager) ClearCache() error {
	// æ¸…é™¤å†…å­˜ä¸­çš„ç¼“å­˜é¡¹
	var keysToDelete []CacheKey
	cm.items.Range(func(key, value interface{}) bool {
		cacheKey := key.(CacheKey)
		keysToDelete = append(keysToDelete, cacheKey)
		return true
	})

	for _, key := range keysToDelete {
		cm.items.Delete(key)
	}

	// æ¸…ç†ç¼“å­˜ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
	entries, err := os.ReadDir(cm.cacheDir)
	if err != nil {
		return fmt.Errorf("failed to read cache directory: %v", err)
	}

	for _, entry := range entries {
		if entry.Name() == "config.json" {
			continue // ä¿ç•™é…ç½®æ–‡ä»¶
		}
		filePath := filepath.Join(cm.cacheDir, entry.Name())
		if err := os.Remove(filePath); err != nil {
			log.Printf("[Cache] ERR Failed to remove file: %s", entry.Name())
		}
	}

	// é‡ç½®ç»Ÿè®¡ä¿¡æ¯
	cm.hitCount.Store(0)
	cm.missCount.Store(0)
	cm.bytesSaved.Store(0)
	cm.formatFallbackHit.Store(0)
	cm.imageCacheHit.Store(0)
	cm.regularCacheHit.Store(0)

	return nil
}

// cleanStaleFiles æ¸…ç†è¿‡æœŸå’Œä¸´æ—¶æ–‡ä»¶
func (cm *CacheManager) cleanStaleFiles() error {
	entries, err := os.ReadDir(cm.cacheDir)
	if err != nil {
		return fmt.Errorf("failed to read cache directory: %v", err)
	}

	for _, entry := range entries {
		if entry.Name() == "config.json" {
			continue // ä¿ç•™é…ç½®æ–‡ä»¶
		}

		filePath := filepath.Join(cm.cacheDir, entry.Name())

		// æ¸…ç†ä¸´æ—¶æ–‡ä»¶
		if strings.HasPrefix(entry.Name(), "temp-") {
			if err := os.Remove(filePath); err != nil {
				log.Printf("[Cache] ERR Failed to remove temp file: %s", entry.Name())
			}
			continue
		}

		// æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä»åœ¨ç¼“å­˜è®°å½•ä¸­
		fileFound := false
		cm.items.Range(func(_, value interface{}) bool {
			item := value.(*CacheItem)
			if item.FilePath == filePath {
				fileFound = true
				return false
			}
			return true
		})

		// å¦‚æœæ–‡ä»¶ä¸åœ¨ç¼“å­˜è®°å½•ä¸­ï¼Œåˆ é™¤å®ƒ
		if !fileFound {
			if err := os.Remove(filePath); err != nil {
				log.Printf("[Cache] ERR Failed to remove stale file: %s", entry.Name())
			}
		}
	}

	return nil
}

// CreateTemp åˆ›å»ºä¸´æ—¶ç¼“å­˜æ–‡ä»¶
func (cm *CacheManager) CreateTemp(key CacheKey, resp *http.Response) (*os.File, error) {
	if !cm.enabled.Load() {
		return nil, fmt.Errorf("cache is disabled")
	}

	// åˆ›å»ºä¸´æ—¶æ–‡ä»¶
	tempFile, err := os.CreateTemp(cm.cacheDir, "temp-*")
	if err != nil {
		return nil, fmt.Errorf("failed to create temp file: %v", err)
	}

	return tempFile, nil
}

// Commit æäº¤ç¼“å­˜æ–‡ä»¶
func (cm *CacheManager) Commit(key CacheKey, tempPath string, resp *http.Response, size int64) error {
	if !cm.enabled.Load() {
		os.Remove(tempPath)
		return fmt.Errorf("cache is disabled")
	}

	// è¯»å–ä¸´æ—¶æ–‡ä»¶å†…å®¹ä»¥è®¡ç®—å“ˆå¸Œ
	tempData, err := os.ReadFile(tempPath)
	if err != nil {
		os.Remove(tempPath)
		return fmt.Errorf("failed to read temp file: %v", err)
	}

	// è®¡ç®—å†…å®¹å“ˆå¸Œï¼Œä¸Putæ–¹æ³•ä¿æŒä¸€è‡´
	contentHash := sha256.Sum256(tempData)
	hashStr := hex.EncodeToString(contentHash[:])

	// æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç›¸åŒå“ˆå¸Œçš„ç¼“å­˜é¡¹
	var existingItem *CacheItem
	cm.items.Range(func(k, v interface{}) bool {
		if item := v.(*CacheItem); item.Hash == hashStr {
			if _, err := os.Stat(item.FilePath); err == nil {
				existingItem = item
				return false
			}
			cm.items.Delete(k)
		}
		return true
	})

	if existingItem != nil {
		// åˆ é™¤ä¸´æ—¶æ–‡ä»¶ï¼Œä½¿ç”¨ç°æœ‰ç¼“å­˜
		os.Remove(tempPath)
		cm.items.Store(key, existingItem)
		log.Printf("[Cache] HIT %s %s (%s) from %s", resp.Request.Method, key.URL, formatBytes(existingItem.Size), utils.GetRequestSource(resp.Request))
		return nil
	}

	// ç”Ÿæˆæœ€ç»ˆçš„ç¼“å­˜æ–‡ä»¶åï¼ˆä½¿ç”¨å†…å®¹å“ˆå¸Œï¼‰
	fileName := hashStr
	filePath := filepath.Join(cm.cacheDir, fileName)

	// é‡å‘½åä¸´æ—¶æ–‡ä»¶
	if err := os.Rename(tempPath, filePath); err != nil {
		os.Remove(tempPath)
		return fmt.Errorf("failed to rename temp file: %v", err)
	}

	// åˆ›å»ºç¼“å­˜é¡¹
	item := &CacheItem{
		FilePath:        filePath,
		ContentType:     resp.Header.Get("Content-Type"),
		ContentEncoding: resp.Header.Get("Content-Encoding"),
		Size:            size,
		LastAccess:      time.Now(),
		Hash:            hashStr,
		CreatedAt:       time.Now(),
		AccessCount:     1,
	}

	cm.items.Store(key, item)
	cm.bytesSaved.Add(size)
	log.Printf("[Cache] NEW %s %s (%s)", resp.Request.Method, key.URL, formatBytes(size))
	return nil
}

// GetConfig è·å–ç¼“å­˜é…ç½®
func (cm *CacheManager) GetConfig() config.CacheConfig {
	return config.CacheConfig{
		MaxAge:       int64(cm.maxAge.Minutes()),
		CleanupTick:  int64(cm.cleanupTick.Minutes()),
		MaxCacheSize: cm.maxCacheSize / (1024 * 1024 * 1024), // è½¬æ¢ä¸ºGB
	}
}

// UpdateConfig æ›´æ–°ç¼“å­˜é…ç½®
func (cm *CacheManager) UpdateConfig(cacheConfig *config.CacheConfig) error {
	if cacheConfig.MaxAge <= 0 || cacheConfig.CleanupTick <= 0 || cacheConfig.MaxCacheSize <= 0 {
		return fmt.Errorf("invalid config values: all values must be positive")
	}

	cm.maxAge = time.Duration(cacheConfig.MaxAge) * time.Minute
	cm.maxCacheSize = cacheConfig.MaxCacheSize * 1024 * 1024 * 1024 // è½¬æ¢ä¸ºå­—èŠ‚

	// å¦‚æœæ¸…ç†é—´éš”å‘ç”Ÿå˜åŒ–ï¼Œé‡å¯æ¸…ç†åç¨‹
	newCleanupTick := time.Duration(cacheConfig.CleanupTick) * time.Minute
	if cm.cleanupTick != newCleanupTick {
		cm.cleanupTick = newCleanupTick
		// åœæ­¢å½“å‰çš„æ¸…ç†åç¨‹
		cm.stopCleanup <- struct{}{}
		// å¯åŠ¨æ–°çš„æ¸…ç†åç¨‹
		cm.startCleanup()
	}

	return nil
}


// startCleanup å¯åŠ¨æ¸…ç†åç¨‹
func (cm *CacheManager) startCleanup() {
	cm.cleanupTimer = time.NewTicker(cm.cleanupTick)
	go func() {
		for {
			select {
			case <-cm.cleanupTimer.C:
				cm.cleanup()
			case <-cm.stopCleanup:
				cm.cleanupTimer.Stop()
				return
			}
		}
	}()
}


// GetExtensionMatcher è·å–ç¼“å­˜çš„ExtensionMatcher
func (cm *CacheManager) GetExtensionMatcher(pathKey string, rules []config.ExtensionRule) *utils.ExtensionMatcher {
	if cm.extensionMatcherCache == nil {
		return utils.NewExtensionMatcher(rules)
	}
	return cm.extensionMatcherCache.GetOrCreate(pathKey, rules)
}

// InvalidateExtensionMatcherPath ä½¿æŒ‡å®šè·¯å¾„çš„ExtensionMatcherç¼“å­˜å¤±æ•ˆ
func (cm *CacheManager) InvalidateExtensionMatcherPath(pathKey string) {
	if cm.extensionMatcherCache != nil {
		cm.extensionMatcherCache.InvalidatePath(pathKey)
	}
}

// InvalidateAllExtensionMatchers æ¸…ç©ºæ‰€æœ‰ExtensionMatcherç¼“å­˜
func (cm *CacheManager) InvalidateAllExtensionMatchers() {
	if cm.extensionMatcherCache != nil {
		cm.extensionMatcherCache.InvalidateAll()
	}
}

// GetExtensionMatcherStats è·å–ExtensionMatcherç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
func (cm *CacheManager) GetExtensionMatcherStats() ExtensionMatcherCacheStats {
	if cm.extensionMatcherCache != nil {
		return cm.extensionMatcherCache.GetStats()
	}
	return ExtensionMatcherCacheStats{}
}

// UpdateExtensionMatcherConfig æ›´æ–°ExtensionMatcherç¼“å­˜é…ç½®
func (cm *CacheManager) UpdateExtensionMatcherConfig(maxAge, cleanupTick time.Duration) {
	if cm.extensionMatcherCache != nil {
		cm.extensionMatcherCache.UpdateConfig(maxAge, cleanupTick)
	}
}

// Stop åœæ­¢ç¼“å­˜ç®¡ç†å™¨ï¼ˆåŒ…æ‹¬ExtensionMatcherç¼“å­˜ï¼‰
func (cm *CacheManager) Stop() {
	// åœæ­¢ä¸»ç¼“å­˜æ¸…ç†
	if cm.cleanupTimer != nil {
		cm.cleanupTimer.Stop()
	}
	close(cm.stopCleanup)

	// åœæ­¢ExtensionMatcherç¼“å­˜
	if cm.extensionMatcherCache != nil {
		cm.extensionMatcherCache.Stop()
	}
}
